{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "401bd3fb-5582-4747-8516-e22371fbc326",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import joblib\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf28cedf-0059-4fbd-94d4-7aa147c443d9",
   "metadata": {},
   "source": [
    "Funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a474c20-d693-497c-b4cb-8520ddf8fce8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ------------------------------------ Load raw data --------------------------------------\n",
    "def load_csv_to_mysql():\n",
    "    try:\n",
    "        csv_path = 'penguins_lter.csv'\n",
    "        df = pd.read_csv(csv_path)\n",
    "\n",
    "        engine = create_engine('mysql+pymysql://user:password@db:3306/db_jupyter')\n",
    "\n",
    "        # Guardar en MySQL\n",
    "        df.to_sql(\"penguins_original\", con=engine, if_exists='replace', index=False)\n",
    "        print(\"✅ Datos originales cargados en MySQL.\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error en load_csv_to_mysql: {e}\")\n",
    "\n",
    "# ------------------------------------ Load transformed data --------------------------------------\n",
    "def preprocesamiento():\n",
    "    try:\n",
    "        engine = create_engine(\"mysql+pymysql://user:password@db:3306/db_jupyter\")\n",
    "\n",
    "        # Leer los datos de MySQL con pd.read_sql en lugar de pd.read_sql_table\n",
    "        df = pd.read_sql(\"SELECT * FROM penguins_original\", con=engine)\n",
    "\n",
    "        # Transformación de \"Date Egg\" a día del año (manejo de NaN)\n",
    "        if \"Date Egg\" in df.columns:\n",
    "            df[\"Date Egg\"] = pd.to_datetime(df[\"Date Egg\"], errors=\"coerce\").dt.dayofyear\n",
    "            df[\"Date Egg\"].fillna(df[\"Date Egg\"].median(), inplace=True)\n",
    "\n",
    "        # Eliminar columnas irrelevantes si existen\n",
    "        cols_to_drop = [\"studyName\", \"Sample Number\", \"Individual ID\", \"Comments\"]\n",
    "        df.drop(columns=[col for col in cols_to_drop if col in df.columns], inplace=True)\n",
    "\n",
    "        # Manejo de valores nulos en columnas numéricas\n",
    "        num_cols = [\"Culmen Length (mm)\", \"Culmen Depth (mm)\", \"Flipper Length (mm)\", \"Body Mass (g)\", \"Delta 15 N (o/oo)\", \"Delta 13 C (o/oo)\"]\n",
    "        for col in num_cols:\n",
    "            if col in df.columns:\n",
    "                df[col].fillna(df[col].mean(), inplace=True)\n",
    "\n",
    "        # Manejo de valores nulos en columnas categóricas\n",
    "        cat_cols = [\"Species\", \"Region\", \"Island\", \"Stage\", \"Clutch Completion\", \"Sex\"]\n",
    "        for col in cat_cols:\n",
    "            if col in df.columns:\n",
    "                df[col].fillna(\"Desconocido\", inplace=True)\n",
    "\n",
    "        # One-Hot Encoding para variables categóricas si existen\n",
    "        df = pd.get_dummies(df, columns=[col for col in cat_cols if col in df.columns], drop_first=True)\n",
    "\n",
    "        # Selección de variables predictoras y objetivo\n",
    "        feature_cols = [\"Culmen Length (mm)\", \"Culmen Depth (mm)\", \"Flipper Length (mm)\"]\n",
    "        target_col = \"Body Mass (g)\"\n",
    "\n",
    "        if not all(col in df.columns for col in feature_cols + [target_col]):\n",
    "            raise ValueError(\"⚠️ Algunas columnas clave no están en los datos procesados.\")\n",
    "\n",
    "        X = df[feature_cols]\n",
    "        y = df[target_col]\n",
    "\n",
    "        # Dividir en entrenamiento y prueba (80%-20%)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "        # Guardar los conjuntos en MySQL\n",
    "        X_train.to_sql(\"train_data_X\", con=engine, if_exists=\"replace\", index=False)\n",
    "        X_test.to_sql(\"test_data_X\", con=engine, if_exists=\"replace\", index=False)\n",
    "        y_train.to_sql(\"train_data_y\", con=engine, if_exists=\"replace\", index=False)\n",
    "        y_test.to_sql(\"test_data_y\", con=engine, if_exists=\"replace\", index=False)\n",
    "\n",
    "        print(\"✅ Preprocesamiento completo. Tablas 'train_data_X', 'train_data_y', 'test_data_X' y 'test_data_y' creadas en MySQL.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error en preprocesamiento: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47398405-0a07-43c1-a1b2-9628a4fa18fa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Datos originales cargados en MySQL.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23/328991044.py:26: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[\"Date Egg\"] = pd.to_datetime(df[\"Date Egg\"], errors=\"coerce\").dt.dayofyear\n",
      "/tmp/ipykernel_23/328991044.py:27: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[\"Date Egg\"].fillna(df[\"Date Egg\"].median(), inplace=True)\n",
      "/tmp/ipykernel_23/328991044.py:37: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].mean(), inplace=True)\n",
      "/tmp/ipykernel_23/328991044.py:43: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(\"Desconocido\", inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Preprocesamiento completo. Tablas 'train_data_X', 'train_data_y', 'test_data_X' y 'test_data_y' creadas en MySQL.\n"
     ]
    }
   ],
   "source": [
    "#truncate_all_tables()\n",
    "load_csv_to_mysql()\n",
    "preprocesamiento()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c25374ef-16e7-40bb-ade5-051e80cca9b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "engine = create_engine(\"mysql+pymysql://user:password@db:3306/db_jupyter\")\n",
    "\n",
    "    \n",
    "# Separar variables predictoras y objetivo\n",
    "X_train = pd.read_sql_table(\"train_data_X\", engine)\n",
    "y_train = pd.read_sql_table(\"train_data_y\", engine).values.ravel()\n",
    "X_test = pd.read_sql_table(\"test_data_X\", engine)\n",
    "y_test = pd.read_sql_table(\"test_data_y\", engine).values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5d3812df-5b13-42e2-a32c-f28202514e0a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/14 03:00:19 INFO mlflow.tracking.fluent: Autologging successfully enabled for sklearn.\n",
      "2025/03/14 03:00:22 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during sklearn autologging: Unable to locate credentials\n"
     ]
    }
   ],
   "source": [
    "# run description (just metadata)\n",
    "desc = \"the simplest possible example\"\n",
    "\n",
    "# connects to the Mlflow tracking server that you started above\n",
    "mlflow.set_tracking_uri(\"http://192.168.1.10:5000\")\n",
    "mlflow.set_experiment(\"mlflow_tracking_pinguins_proofs\")\n",
    "\n",
    "mlflow.autolog(log_model_signatures=True, log_input_examples=True)\n",
    "\n",
    "\n",
    "# executes the run\n",
    "with mlflow.start_run(run_name=\"Random_forest_no_params\", description=desc) as run:\n",
    "    # Entrenar RandomForest\n",
    "    rf_model = RandomForestRegressor()\n",
    "    rf_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "587fb100-2fa5-4464-8dc4-2cd4e907270d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/14 02:52:07 INFO mlflow.tracking.fluent: Experiment with name 'mlflow_tracking_pinguins_proofs' does not exist. Creating a new experiment.\n",
      "2025/03/14 02:52:08 INFO mlflow.tracking.fluent: Autologging successfully enabled for sklearn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando GradientBoostingRegressor...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEntrenando GradientBoostingRegressor...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     15\u001b[0m gb_model \u001b[38;5;241m=\u001b[39m GradientBoostingRegressor()\n\u001b[0;32m---> 16\u001b[0m gb_model\u001b[38;5;241m.\u001b[39mfit(\u001b[43mX_train\u001b[49m, y_train)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "# run description (just metadata)\n",
    "desc = \"the simplest possible example\"\n",
    "\n",
    "# connects to the Mlflow tracking server that you started above\n",
    "mlflow.set_tracking_uri(\"http://192.168.1.10:5000\")\n",
    "mlflow.set_experiment(\"mlflow_tracking_pinguins_proofs\")\n",
    "\n",
    "mlflow.autolog(log_model_signatures=True, log_input_examples=True)\n",
    "\n",
    "\n",
    "# executes the run\n",
    "with mlflow.start_run(run_name=\"no_artifacts_logged2\", description=desc) as run:\n",
    "    # Entrenar GradientBoostingRegressor\n",
    "    print(\"Entrenando GradientBoostingRegressor...\")\n",
    "    gb_model = GradientBoostingRegressor()\n",
    "    gb_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9efa36-a24a-4649-ba38-092f5ab1554e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# loads the diabetes dataset\n",
    "db = load_diabetes()\n",
    "X_train, X_test, y_train, y_test = train_test_split(db.data, db.target)\n",
    "\n",
    "# run description (just metadata)\n",
    "desc = \"the simplest possible example\"\n",
    "\n",
    "# connects to the Mlflow tracking server that you started above\n",
    "mlflow.set_tracking_uri(\"http://10.43.101.149:5000\")\n",
    "mlflow.set_experiment(\"mlflow_tracking_examples_class\")\n",
    "\n",
    "# executes the run\n",
    "with mlflow.start_run(run_name=\"no_artifacts_logged\", description=desc) as run:\n",
    "    rf = RandomForestRegressor(n_estimators=100, max_depth=6, max_features=3)\n",
    "    rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181deba3-175e-4f6c-b5a6-0bb9eee26aa6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7c6d46-9ae3-4cbb-a5e6-233ab1d6012c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# loads the diabetes dataset\n",
    "db = load_diabetes()\n",
    "X_train, X_test, y_train, y_test = train_test_split(db.data, db.target)\n",
    "\n",
    "# run description (just metadata)\n",
    "desc = \"the simplest possible example\"\n",
    "\n",
    "# connects to the Mlflow tracking server that you started above\n",
    "mlflow.set_tracking_uri(\"http://10.43.101.149:5000\")\n",
    "mlflow.set_experiment(\"mlflow_tracking_examples_class\")\n",
    "\n",
    "\n",
    "with mlflow.start_run(run_name=\"params_no_artifacts_logged\") as run:\n",
    "\n",
    "    params = {\"n_estimators\":100, \"max_depth\":6, \"max_features\":3}\n",
    "\n",
    "    rf = RandomForestRegressor(**params)\n",
    "    rf.fit(X_train, y_train)\n",
    "\n",
    "    mlflow.log_params(params)\n",
    "    mlflow.log_param(\"my_extra_param\", \"extra_param_value\")\n",
    "    mlflow.log_metric(\"my_metric\", 0.8)\n",
    "    mlflow.set_tag(\"my_tag\", \"my_tag_value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019f642c-6e02-408a-afd9-4f2fba6f6bee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dbd4e91-c764-4b6f-8a56-97e652fcac33",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "import os\n",
    "os.environ['MLFLOW_S3_ENDPOINT_URL'] = \"http://10.43.101.149:9000\"\n",
    "os.environ['AWS_ACCESS_KEY_ID'] = 'admin'\n",
    "os.environ['AWS_SECRET_ACCESS_KEY'] = 'supersecret'\n",
    "\n",
    "# loads the diabetes dataset\n",
    "db = load_diabetes()\n",
    "X_train, X_test, y_train, y_test = train_test_split(db.data, db.target)\n",
    "\n",
    "# run description (just metadata)\n",
    "desc = \"the simplest possible example\"\n",
    "\n",
    "# connects to the Mlflow tracking server that you started above\n",
    "mlflow.set_tracking_uri(\"http://10.43.101.149:5000\")\n",
    "mlflow.set_experiment(\"mlflow_tracking_examples_class\")\n",
    "\n",
    "with mlflow.start_run(run_name=\"logged_artifacts\") as run:\n",
    "    params = {\"n_estimators\":100, \"max_depth\":6, \"max_features\":3}\n",
    "\n",
    "    rf = RandomForestRegressor(**params)\n",
    "    rf.fit(X_train, y_train)\n",
    "\n",
    "    mlflow.log_params(params)\n",
    "    mlflow.sklearn.log_model(\n",
    "      sk_model=rf,\n",
    "      artifact_path=\"random_forest_regressor\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e03edb6-d23f-43ba-aaaf-ea9a905eec3c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('tracking uri:', mlflow.get_tracking_uri())\n",
    "print('artifact uri:', mlflow.get_artifact_uri())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a5fe06-f74c-4d27-be39-a38b1c4fae0e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "import os\n",
    "os.environ['MLFLOW_S3_ENDPOINT_URL'] = \"http://10.43.101.149:9000\"\n",
    "os.environ['AWS_ACCESS_KEY_ID'] = 'admin'\n",
    "os.environ['AWS_SECRET_ACCESS_KEY'] = 'supersecret'\n",
    "\n",
    "db = load_diabetes()\n",
    "X_train, X_test, y_train, y_test = train_test_split(db.data, db.target)\n",
    "\n",
    "# connect to mlflow\n",
    "mlflow.set_tracking_uri(\"http://10.43.101.149:5000\")\n",
    "mlflow.set_experiment(\"mlflow_tracking_examples_class2\")\n",
    "\n",
    "# this is the magical stuff\n",
    "mlflow.autolog(log_input_examples=True, log_model_signatures=True)\n",
    "\n",
    "# train the model\n",
    "rf = RandomForestRegressor(n_estimators=100, max_depth=6, max_features=3)\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59f0b90-8d96-4378-988f-c50824cd4998",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0037907-07ed-4c8a-b4fa-d00e1cb11378",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "import os\n",
    "os.environ['MLFLOW_S3_ENDPOINT_URL'] = \"http://10.43.101.149:9000\"\n",
    "os.environ['AWS_ACCESS_KEY_ID'] = 'admin'\n",
    "os.environ['AWS_SECRET_ACCESS_KEY'] = 'supersecret'\n",
    "\n",
    "db = load_diabetes()\n",
    "X_train, X_test, y_train, y_test = train_test_split(db.data, db.target)\n",
    "\n",
    "# connect to mlflow\n",
    "mlflow.set_tracking_uri(\"http://10.43.101.149:5000\")\n",
    "mlflow.set_experiment(\"mlflow_tracking_examples_class\")\n",
    "\n",
    "mlflow.autolog(log_model_signatures=True, log_input_examples=True)\n",
    "\n",
    "with mlflow.start_run(run_name=\"autolog_with_named_run\") as run:\n",
    "    rf = RandomForestRegressor(n_estimators=100, max_depth=6, max_features=3)\n",
    "    rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e15e37-f713-413b-9c4e-cae2cf66c64b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134fe830-86f9-474f-a1d4-5d3371434461",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "import os\n",
    "os.environ['MLFLOW_S3_ENDPOINT_URL'] = \"http://10.43.101.149:9000\"\n",
    "os.environ['AWS_ACCESS_KEY_ID'] = 'admin'\n",
    "os.environ['AWS_SECRET_ACCESS_KEY'] = 'supersecret'\n",
    "\n",
    "db = load_diabetes()\n",
    "X_train, X_test, y_train, y_test = train_test_split(db.data, db.target)\n",
    "\n",
    "# connect to mlflow\n",
    "mlflow.set_tracking_uri(\"http://10.43.101.149:5000\")\n",
    "mlflow.set_experiment(\"mlflow_tracking_examples_class\")\n",
    "\n",
    "mlflow.autolog(log_model_signatures=True, log_input_examples=True)\n",
    "\n",
    "with mlflow.start_run(run_name=\"main_run_for_nested\") as run:\n",
    "    for estimators in range(20, 100, 20):\n",
    "        with mlflow.start_run(run_name=f\"nested_{estimators}_estimators\", nested=True) as nested:\n",
    "            rf = RandomForestRegressor(n_estimators=estimators, max_depth=6, max_features=3)\n",
    "            rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4074e92-d02b-4d4d-a58e-5f596fe2e946",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6a7a07-025d-4660-8184-8f578135f1f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8a1e56-f9aa-4732-930d-94f62c202435",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import os\n",
    "os.environ['MLFLOW_S3_ENDPOINT_URL'] = \"http://10.43.101.149:9000\"\n",
    "os.environ['AWS_ACCESS_KEY_ID'] = 'admin'\n",
    "os.environ['AWS_SECRET_ACCESS_KEY'] = 'supersecret'\n",
    "\n",
    "db = load_diabetes()\n",
    "X_train, X_test, y_train, y_test = train_test_split(db.data, db.target)\n",
    "\n",
    "# connect to mlflow\n",
    "mlflow.set_tracking_uri(\"http://10.43.101.149:5000\")\n",
    "mlflow.set_experiment(\"mlflow_tracking_examples_class1\")\n",
    "\n",
    "mlflow.autolog(log_model_signatures=True, log_input_examples=True)\n",
    "\n",
    "params = {\n",
    "  \"n_estimators\": [33, 66, 200],\n",
    "  \"max_depth\": [2, 4, 6],\n",
    "  \"max_features\": [3, 4, 5]\n",
    "}\n",
    "\n",
    "rf = RandomForestRegressor()\n",
    "searcher = GridSearchCV(estimator=rf, param_grid=params)\n",
    "\n",
    "with mlflow.start_run(run_name=\"autolog_with_grid_search\") as run:\n",
    "    searcher.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73623d3a-e244-46e6-bc31-2d13050d7b42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
